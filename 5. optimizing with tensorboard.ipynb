{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many parameters we can optmize, for instance, the learning rate, optimizing function, number and types of layers, neurons per layer\n",
    "\n",
    "Let's tweak the number of layers and nodes per layer for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "home = os.getenv('HOME')\n",
    "datadir = os.path.join(home, 'Pictures', 'kagglecatsanddogs_3367a', 'PetImages')\n",
    "\n",
    "# tensorflow variables\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.33)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(os.path.join(datadir, 'X.pkl'), 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "    \n",
    "with open(os.path.join(datadir, 'y.pkl'), 'rb') as file:\n",
    "    y = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24946, 50, 50, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1-conv-32-nodes-1-dense-1548438334']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 128us/step - loss: 0.6266 - acc: 0.6478 - val_loss: 0.5736 - val_acc: 0.7102\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 2s 91us/step - loss: 0.5503 - acc: 0.7253 - val_loss: 0.5522 - val_acc: 0.7220\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 2s 91us/step - loss: 0.5187 - acc: 0.7490 - val_loss: 0.5362 - val_acc: 0.7347\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 93us/step - loss: 0.4930 - acc: 0.7675 - val_loss: 0.5378 - val_acc: 0.7331\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 2s 88us/step - loss: 0.4753 - acc: 0.7787 - val_loss: 0.5248 - val_acc: 0.7393\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 2s 106us/step - loss: 0.4595 - acc: 0.7879 - val_loss: 0.5334 - val_acc: 0.7357\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 2s 118us/step - loss: 0.4511 - acc: 0.7900 - val_loss: 0.5261 - val_acc: 0.7457\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 2s 93us/step - loss: 0.4397 - acc: 0.7989 - val_loss: 0.5271 - val_acc: 0.7451\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 2s 87us/step - loss: 0.4302 - acc: 0.8013 - val_loss: 0.5370 - val_acc: 0.7413\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 2s 89us/step - loss: 0.4193 - acc: 0.8093 - val_loss: 0.5273 - val_acc: 0.7445\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 2s 83us/step - loss: 0.4115 - acc: 0.8112 - val_loss: 0.5402 - val_acc: 0.7415\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 2s 95us/step - loss: 0.4034 - acc: 0.8164 - val_loss: 0.5420 - val_acc: 0.7435\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.3946 - acc: 0.8214 - val_loss: 0.5434 - val_acc: 0.7433\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 2s 91us/step - loss: 0.3865 - acc: 0.8275 - val_loss: 0.5586 - val_acc: 0.7341\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 2s 91us/step - loss: 0.3772 - acc: 0.8308 - val_loss: 0.5448 - val_acc: 0.7401\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 99us/step - loss: 0.3714 - acc: 0.8351 - val_loss: 0.5750 - val_acc: 0.7253\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 99us/step - loss: 0.3653 - acc: 0.8386 - val_loss: 0.5605 - val_acc: 0.7419\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 2s 92us/step - loss: 0.3565 - acc: 0.8447 - val_loss: 0.5731 - val_acc: 0.7335\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 88us/step - loss: 0.3521 - acc: 0.8453 - val_loss: 0.5704 - val_acc: 0.7403\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 2s 95us/step - loss: 0.3411 - acc: 0.8511 - val_loss: 0.5799 - val_acc: 0.7353\n",
      "['2-conv-32-nodes-2-dense-1548438373']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.6301 - acc: 0.6393 - val_loss: 0.5804 - val_acc: 0.7044\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 2s 110us/step - loss: 0.5387 - acc: 0.7328 - val_loss: 0.5214 - val_acc: 0.7491\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 2s 108us/step - loss: 0.5008 - acc: 0.7602 - val_loss: 0.5030 - val_acc: 0.7597\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 112us/step - loss: 0.4786 - acc: 0.7709 - val_loss: 0.4846 - val_acc: 0.7701\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 2s 112us/step - loss: 0.4627 - acc: 0.7854 - val_loss: 0.5125 - val_acc: 0.7537\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 2s 112us/step - loss: 0.4504 - acc: 0.7911 - val_loss: 0.4765 - val_acc: 0.7810\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 2s 122us/step - loss: 0.4353 - acc: 0.8009 - val_loss: 0.4675 - val_acc: 0.7822\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.4205 - acc: 0.8092 - val_loss: 0.4820 - val_acc: 0.7739\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 2s 104us/step - loss: 0.4125 - acc: 0.8157 - val_loss: 0.4655 - val_acc: 0.7870\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 2s 111us/step - loss: 0.4019 - acc: 0.8202 - val_loss: 0.4596 - val_acc: 0.7924\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 2s 104us/step - loss: 0.3949 - acc: 0.8238 - val_loss: 0.4684 - val_acc: 0.7864\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 2s 105us/step - loss: 0.3806 - acc: 0.8310 - val_loss: 0.4521 - val_acc: 0.7896\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 2s 107us/step - loss: 0.3744 - acc: 0.8355 - val_loss: 0.4540 - val_acc: 0.7978\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 2s 104us/step - loss: 0.3651 - acc: 0.8375 - val_loss: 0.4544 - val_acc: 0.7920\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 2s 107us/step - loss: 0.3541 - acc: 0.8414 - val_loss: 0.4500 - val_acc: 0.7972\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.3466 - acc: 0.8468 - val_loss: 0.4470 - val_acc: 0.8012\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.3381 - acc: 0.8517 - val_loss: 0.4514 - val_acc: 0.7976\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.3299 - acc: 0.8580 - val_loss: 0.4610 - val_acc: 0.7996\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 112us/step - loss: 0.3220 - acc: 0.8579 - val_loss: 0.4584 - val_acc: 0.8008\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.3159 - acc: 0.8624 - val_loss: 0.4686 - val_acc: 0.7930\n",
      "['3-conv-32-nodes-3-dense-1548438418']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 145us/step - loss: 0.6515 - acc: 0.6078 - val_loss: 0.6043 - val_acc: 0.6768\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 127us/step - loss: 0.5519 - acc: 0.7220 - val_loss: 0.5562 - val_acc: 0.7112\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 2s 125us/step - loss: 0.5028 - acc: 0.7580 - val_loss: 0.5126 - val_acc: 0.7505\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.4717 - acc: 0.7779 - val_loss: 0.5040 - val_acc: 0.7677\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 2s 124us/step - loss: 0.4481 - acc: 0.7934 - val_loss: 0.4648 - val_acc: 0.7830\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 2s 124us/step - loss: 0.4270 - acc: 0.8022 - val_loss: 0.4651 - val_acc: 0.7846\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 128us/step - loss: 0.4045 - acc: 0.8163 - val_loss: 0.4601 - val_acc: 0.7874\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.3867 - acc: 0.8250 - val_loss: 0.4390 - val_acc: 0.7930\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 126us/step - loss: 0.3716 - acc: 0.8345 - val_loss: 0.4568 - val_acc: 0.7872\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 2s 125us/step - loss: 0.3520 - acc: 0.8449 - val_loss: 0.4307 - val_acc: 0.8000\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 2s 124us/step - loss: 0.3341 - acc: 0.8518 - val_loss: 0.4219 - val_acc: 0.8058\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 125us/step - loss: 0.3170 - acc: 0.8627 - val_loss: 0.4298 - val_acc: 0.8004\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.3051 - acc: 0.8671 - val_loss: 0.4210 - val_acc: 0.8104\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.2869 - acc: 0.8776 - val_loss: 0.4390 - val_acc: 0.8060\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 2s 125us/step - loss: 0.2735 - acc: 0.8832 - val_loss: 0.4236 - val_acc: 0.8156\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 125us/step - loss: 0.2601 - acc: 0.8909 - val_loss: 0.4391 - val_acc: 0.8106\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.2510 - acc: 0.8960 - val_loss: 0.4467 - val_acc: 0.8160\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.2370 - acc: 0.9001 - val_loss: 0.4492 - val_acc: 0.8152\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 124us/step - loss: 0.2240 - acc: 0.9073 - val_loss: 0.4694 - val_acc: 0.8132\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 131us/step - loss: 0.2119 - acc: 0.9133 - val_loss: 0.4742 - val_acc: 0.8088\n",
      "['1-conv-64-nodes-1-dense-1548438470']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.6275 - acc: 0.6501 - val_loss: 0.6048 - val_acc: 0.6685\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 127us/step - loss: 0.5442 - acc: 0.7258 - val_loss: 0.5301 - val_acc: 0.7403\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.5067 - acc: 0.7560 - val_loss: 0.5346 - val_acc: 0.7389\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 3s 157us/step - loss: 0.4831 - acc: 0.7736 - val_loss: 0.5233 - val_acc: 0.7413\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 129us/step - loss: 0.4632 - acc: 0.7817 - val_loss: 0.5319 - val_acc: 0.7425\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 129us/step - loss: 0.4456 - acc: 0.7946 - val_loss: 0.5339 - val_acc: 0.7445\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 126us/step - loss: 0.4299 - acc: 0.8027 - val_loss: 0.5589 - val_acc: 0.7335\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 126us/step - loss: 0.4142 - acc: 0.8106 - val_loss: 0.5298 - val_acc: 0.7449\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 127us/step - loss: 0.3980 - acc: 0.8197 - val_loss: 0.5345 - val_acc: 0.7461\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 127us/step - loss: 0.3833 - acc: 0.8293 - val_loss: 0.5502 - val_acc: 0.7363\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 128us/step - loss: 0.3720 - acc: 0.8333 - val_loss: 0.5477 - val_acc: 0.7425\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 137us/step - loss: 0.3562 - acc: 0.8435 - val_loss: 0.5569 - val_acc: 0.7407\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 174us/step - loss: 0.3455 - acc: 0.8486 - val_loss: 0.5776 - val_acc: 0.7369\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 141us/step - loss: 0.3323 - acc: 0.8582 - val_loss: 0.5747 - val_acc: 0.7401\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 148us/step - loss: 0.3185 - acc: 0.8652 - val_loss: 0.5828 - val_acc: 0.7275\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 129us/step - loss: 0.3065 - acc: 0.8724 - val_loss: 0.5746 - val_acc: 0.7407\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 131us/step - loss: 0.2926 - acc: 0.8799 - val_loss: 0.5938 - val_acc: 0.7365\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 129us/step - loss: 0.2811 - acc: 0.8843 - val_loss: 0.5999 - val_acc: 0.7347\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 128us/step - loss: 0.2721 - acc: 0.8904 - val_loss: 0.6109 - val_acc: 0.7327\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 129us/step - loss: 0.2589 - acc: 0.8970 - val_loss: 0.6224 - val_acc: 0.7301\n",
      "['2-conv-64-nodes-2-dense-1548438524']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 186us/step - loss: 0.6220 - acc: 0.6482 - val_loss: 0.5877 - val_acc: 0.6922\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.5375 - acc: 0.7325 - val_loss: 0.5099 - val_acc: 0.7517\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 4s 180us/step - loss: 0.4987 - acc: 0.7574 - val_loss: 0.5291 - val_acc: 0.7457\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.4726 - acc: 0.7781 - val_loss: 0.4867 - val_acc: 0.7679\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 154us/step - loss: 0.4507 - acc: 0.7901 - val_loss: 0.4853 - val_acc: 0.7683\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 155us/step - loss: 0.4279 - acc: 0.8030 - val_loss: 0.4697 - val_acc: 0.7806\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 154us/step - loss: 0.4078 - acc: 0.8150 - val_loss: 0.4485 - val_acc: 0.7904\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 154us/step - loss: 0.3918 - acc: 0.8236 - val_loss: 0.4588 - val_acc: 0.7896\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 148us/step - loss: 0.3736 - acc: 0.8336 - val_loss: 0.4687 - val_acc: 0.7904\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 140us/step - loss: 0.3576 - acc: 0.8433 - val_loss: 0.4711 - val_acc: 0.7812\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.3451 - acc: 0.8473 - val_loss: 0.4454 - val_acc: 0.8020\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.3239 - acc: 0.8588 - val_loss: 0.4432 - val_acc: 0.8020\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 146us/step - loss: 0.3151 - acc: 0.8632 - val_loss: 0.4549 - val_acc: 0.7984\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 143us/step - loss: 0.3029 - acc: 0.8682 - val_loss: 0.4413 - val_acc: 0.8044\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.2870 - acc: 0.8765 - val_loss: 0.4546 - val_acc: 0.8056\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.2794 - acc: 0.8799 - val_loss: 0.4508 - val_acc: 0.8058\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.2622 - acc: 0.8887 - val_loss: 0.4668 - val_acc: 0.8000\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.2510 - acc: 0.8929 - val_loss: 0.4743 - val_acc: 0.8062\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 138us/step - loss: 0.2450 - acc: 0.8982 - val_loss: 0.4943 - val_acc: 0.7998\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.2347 - acc: 0.9025 - val_loss: 0.4853 - val_acc: 0.8060\n",
      "['3-conv-64-nodes-3-dense-1548438585']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 181us/step - loss: 0.6520 - acc: 0.6082 - val_loss: 0.5963 - val_acc: 0.6910\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 4s 209us/step - loss: 0.5636 - acc: 0.7092 - val_loss: 0.5340 - val_acc: 0.7411\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.5000 - acc: 0.7578 - val_loss: 0.4980 - val_acc: 0.7623\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.4602 - acc: 0.7831 - val_loss: 0.4808 - val_acc: 0.7707\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 4s 211us/step - loss: 0.4323 - acc: 0.7998 - val_loss: 0.4697 - val_acc: 0.7780\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 171us/step - loss: 0.4001 - acc: 0.8193 - val_loss: 0.4727 - val_acc: 0.7788\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 173us/step - loss: 0.3775 - acc: 0.8300 - val_loss: 0.4445 - val_acc: 0.7988\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 173us/step - loss: 0.3556 - acc: 0.8428 - val_loss: 0.4751 - val_acc: 0.7816\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.3350 - acc: 0.8519 - val_loss: 0.4478 - val_acc: 0.7994\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.3143 - acc: 0.8623 - val_loss: 0.4440 - val_acc: 0.8076\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.2922 - acc: 0.8727 - val_loss: 0.4444 - val_acc: 0.8074\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.2737 - acc: 0.8846 - val_loss: 0.4762 - val_acc: 0.7982\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.2564 - acc: 0.8913 - val_loss: 0.4666 - val_acc: 0.8078\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.2389 - acc: 0.8996 - val_loss: 0.4686 - val_acc: 0.8040\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 3s 169us/step - loss: 0.2196 - acc: 0.9108 - val_loss: 0.5285 - val_acc: 0.8046\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 166us/step - loss: 0.2032 - acc: 0.9187 - val_loss: 0.5218 - val_acc: 0.8050\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.1873 - acc: 0.9236 - val_loss: 0.5228 - val_acc: 0.8142\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.1753 - acc: 0.9304 - val_loss: 0.5421 - val_acc: 0.7998\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.1577 - acc: 0.9373 - val_loss: 0.5635 - val_acc: 0.8090\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.1486 - acc: 0.9430 - val_loss: 0.5790 - val_acc: 0.8042\n",
      "['1-conv-128-nodes-1-dense-1548438655']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 202us/step - loss: 0.6105 - acc: 0.6631 - val_loss: 0.5667 - val_acc: 0.7158\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 4s 205us/step - loss: 0.5358 - acc: 0.7346 - val_loss: 0.5332 - val_acc: 0.7345\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 4s 190us/step - loss: 0.5018 - acc: 0.7591 - val_loss: 0.5296 - val_acc: 0.7391\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 4s 189us/step - loss: 0.4760 - acc: 0.7756 - val_loss: 0.5469 - val_acc: 0.7279\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 4s 191us/step - loss: 0.4493 - acc: 0.7892 - val_loss: 0.5740 - val_acc: 0.7253\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 4s 192us/step - loss: 0.4286 - acc: 0.8038 - val_loss: 0.5393 - val_acc: 0.7437\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 4s 190us/step - loss: 0.4067 - acc: 0.8139 - val_loss: 0.5421 - val_acc: 0.7383\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 4s 183us/step - loss: 0.3846 - acc: 0.8279 - val_loss: 0.5468 - val_acc: 0.7415\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 4s 204us/step - loss: 0.3652 - acc: 0.8374 - val_loss: 0.5508 - val_acc: 0.7337\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 4s 197us/step - loss: 0.3426 - acc: 0.8496 - val_loss: 0.6099 - val_acc: 0.7293\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 4s 188us/step - loss: 0.3256 - acc: 0.8603 - val_loss: 0.5851 - val_acc: 0.7285\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 4s 194us/step - loss: 0.3040 - acc: 0.8738 - val_loss: 0.6500 - val_acc: 0.7136\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 4s 198us/step - loss: 0.2880 - acc: 0.8809 - val_loss: 0.5994 - val_acc: 0.7365\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 4s 190us/step - loss: 0.2712 - acc: 0.8897 - val_loss: 0.6158 - val_acc: 0.7371\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 4s 189us/step - loss: 0.2568 - acc: 0.8960 - val_loss: 0.6174 - val_acc: 0.7321\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 4s 190us/step - loss: 0.2379 - acc: 0.9083 - val_loss: 0.6327 - val_acc: 0.7295\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 4s 204us/step - loss: 0.2229 - acc: 0.9169 - val_loss: 0.6438 - val_acc: 0.7317\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 4s 193us/step - loss: 0.2122 - acc: 0.9208 - val_loss: 0.6651 - val_acc: 0.7377\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 4s 189us/step - loss: 0.1982 - acc: 0.9291 - val_loss: 0.6680 - val_acc: 0.7365\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 4s 189us/step - loss: 0.1824 - acc: 0.9377 - val_loss: 0.7069 - val_acc: 0.7263\n",
      "['2-conv-128-nodes-2-dense-1548438734']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 5s 263us/step - loss: 0.6109 - acc: 0.6594 - val_loss: 0.5570 - val_acc: 0.7222\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 5s 248us/step - loss: 0.5118 - acc: 0.7506 - val_loss: 0.5091 - val_acc: 0.7515\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 5s 248us/step - loss: 0.4739 - acc: 0.7768 - val_loss: 0.4755 - val_acc: 0.7766\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 5s 264us/step - loss: 0.4390 - acc: 0.7992 - val_loss: 0.4606 - val_acc: 0.7854\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 5s 256us/step - loss: 0.4117 - acc: 0.8128 - val_loss: 0.4975 - val_acc: 0.7619\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 5s 253us/step - loss: 0.3834 - acc: 0.8291 - val_loss: 0.4411 - val_acc: 0.7938\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 5s 247us/step - loss: 0.3546 - acc: 0.8412 - val_loss: 0.4371 - val_acc: 0.8018\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 5s 256us/step - loss: 0.3288 - acc: 0.8570 - val_loss: 0.4328 - val_acc: 0.8062\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 5s 252us/step - loss: 0.3063 - acc: 0.8712 - val_loss: 0.4364 - val_acc: 0.8004\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 5s 251us/step - loss: 0.2826 - acc: 0.8783 - val_loss: 0.4341 - val_acc: 0.8164\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 5s 253us/step - loss: 0.2650 - acc: 0.8887 - val_loss: 0.4546 - val_acc: 0.8072\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 5s 249us/step - loss: 0.2433 - acc: 0.8974 - val_loss: 0.4650 - val_acc: 0.8098\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 5s 250us/step - loss: 0.2233 - acc: 0.9075 - val_loss: 0.4834 - val_acc: 0.8086\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 5s 249us/step - loss: 0.2038 - acc: 0.9177 - val_loss: 0.4810 - val_acc: 0.8082\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 5s 248us/step - loss: 0.1863 - acc: 0.9248 - val_loss: 0.4996 - val_acc: 0.8092\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 5s 255us/step - loss: 0.1695 - acc: 0.9338 - val_loss: 0.5287 - val_acc: 0.8012\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 5s 248us/step - loss: 0.1518 - acc: 0.9409 - val_loss: 0.5513 - val_acc: 0.8016\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 5s 248us/step - loss: 0.1391 - acc: 0.9474 - val_loss: 0.5739 - val_acc: 0.7988\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 5s 250us/step - loss: 0.1276 - acc: 0.9516 - val_loss: 0.7229 - val_acc: 0.7774\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 5s 249us/step - loss: 0.1150 - acc: 0.9592 - val_loss: 0.6328 - val_acc: 0.8078\n",
      "['3-conv-128-nodes-3-dense-1548438835']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 6s 300us/step - loss: 0.6521 - acc: 0.6084 - val_loss: 0.6101 - val_acc: 0.6687\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 6s 278us/step - loss: 0.5437 - acc: 0.7272 - val_loss: 0.5159 - val_acc: 0.7491\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 6s 312us/step - loss: 0.4762 - acc: 0.7746 - val_loss: 0.4888 - val_acc: 0.7691\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 6s 282us/step - loss: 0.4325 - acc: 0.7998 - val_loss: 0.4575 - val_acc: 0.7898\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 6s 277us/step - loss: 0.3960 - acc: 0.8230 - val_loss: 0.4280 - val_acc: 0.8034\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 5s 273us/step - loss: 0.3620 - acc: 0.8368 - val_loss: 0.4420 - val_acc: 0.8054\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 5s 272us/step - loss: 0.3267 - acc: 0.8566 - val_loss: 0.4127 - val_acc: 0.8160\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 6s 281us/step - loss: 0.3026 - acc: 0.8675 - val_loss: 0.4115 - val_acc: 0.8186\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 5s 273us/step - loss: 0.2706 - acc: 0.8849 - val_loss: 0.4125 - val_acc: 0.8168\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 5s 273us/step - loss: 0.2472 - acc: 0.8964 - val_loss: 0.4231 - val_acc: 0.8128\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 5s 272us/step - loss: 0.2146 - acc: 0.9108 - val_loss: 0.4588 - val_acc: 0.8076\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 5s 273us/step - loss: 0.1911 - acc: 0.9223 - val_loss: 0.4802 - val_acc: 0.8064\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 5s 273us/step - loss: 0.1686 - acc: 0.9331 - val_loss: 0.4929 - val_acc: 0.8150\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 6s 280us/step - loss: 0.1414 - acc: 0.9449 - val_loss: 0.5258 - val_acc: 0.8124\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 5s 272us/step - loss: 0.1186 - acc: 0.9561 - val_loss: 0.5612 - val_acc: 0.8170\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 5s 272us/step - loss: 0.1032 - acc: 0.9614 - val_loss: 0.6151 - val_acc: 0.8188\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 5s 272us/step - loss: 0.0823 - acc: 0.9694 - val_loss: 0.7260 - val_acc: 0.8070\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 5s 274us/step - loss: 0.0722 - acc: 0.9739 - val_loss: 0.7073 - val_acc: 0.8116\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 6s 300us/step - loss: 0.0622 - acc: 0.9776 - val_loss: 0.7571 - val_acc: 0.8058\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 5s 274us/step - loss: 0.0522 - acc: 0.9828 - val_loss: 0.8411 - val_acc: 0.8086\n",
      "['1-conv-32-nodes-1-dense-1548438948']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 141us/step - loss: 0.6156 - acc: 0.6556 - val_loss: 0.5654 - val_acc: 0.7216\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.5436 - acc: 0.7283 - val_loss: 0.5517 - val_acc: 0.7246\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 2s 119us/step - loss: 0.5060 - acc: 0.7549 - val_loss: 0.5285 - val_acc: 0.7423\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 117us/step - loss: 0.4781 - acc: 0.7754 - val_loss: 0.5270 - val_acc: 0.7481\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 2s 118us/step - loss: 0.4559 - acc: 0.7871 - val_loss: 0.5284 - val_acc: 0.7461\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 2s 118us/step - loss: 0.4376 - acc: 0.7953 - val_loss: 0.5323 - val_acc: 0.7447\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 2s 118us/step - loss: 0.4192 - acc: 0.8050 - val_loss: 0.5430 - val_acc: 0.7393\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 2s 117us/step - loss: 0.3975 - acc: 0.8196 - val_loss: 0.5526 - val_acc: 0.7393\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 146us/step - loss: 0.3765 - acc: 0.8305 - val_loss: 0.6191 - val_acc: 0.7230\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 2s 117us/step - loss: 0.3556 - acc: 0.8434 - val_loss: 0.5836 - val_acc: 0.7435\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 2s 124us/step - loss: 0.3357 - acc: 0.8521 - val_loss: 0.6198 - val_acc: 0.7293\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 2s 108us/step - loss: 0.3109 - acc: 0.8647 - val_loss: 0.6435 - val_acc: 0.7230\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 2s 117us/step - loss: 0.2864 - acc: 0.8775 - val_loss: 0.6604 - val_acc: 0.7331\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.2685 - acc: 0.8863 - val_loss: 0.7158 - val_acc: 0.7166\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.2480 - acc: 0.8969 - val_loss: 0.7191 - val_acc: 0.7166\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.2267 - acc: 0.9074 - val_loss: 0.7626 - val_acc: 0.7246\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 117us/step - loss: 0.2072 - acc: 0.9178 - val_loss: 0.8435 - val_acc: 0.7261\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 2s 116us/step - loss: 0.1913 - acc: 0.9225 - val_loss: 0.8627 - val_acc: 0.7148\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.1721 - acc: 0.9342 - val_loss: 0.9293 - val_acc: 0.7100\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.1577 - acc: 0.9387 - val_loss: 1.0280 - val_acc: 0.6904\n",
      "['2-conv-32-nodes-2-dense-1548438997']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 151us/step - loss: 0.6227 - acc: 0.6447 - val_loss: 0.5476 - val_acc: 0.7305\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.5306 - acc: 0.7384 - val_loss: 0.5076 - val_acc: 0.7589\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.4887 - acc: 0.7688 - val_loss: 0.4836 - val_acc: 0.7671\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 118us/step - loss: 0.4632 - acc: 0.7824 - val_loss: 0.4759 - val_acc: 0.7711\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 130us/step - loss: 0.4404 - acc: 0.7918 - val_loss: 0.4712 - val_acc: 0.7766\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 127us/step - loss: 0.4198 - acc: 0.8068 - val_loss: 0.4562 - val_acc: 0.7842\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 2s 122us/step - loss: 0.3987 - acc: 0.8179 - val_loss: 0.4569 - val_acc: 0.7818\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 126us/step - loss: 0.3797 - acc: 0.8294 - val_loss: 0.4727 - val_acc: 0.7844\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 2s 118us/step - loss: 0.3558 - acc: 0.8397 - val_loss: 0.4598 - val_acc: 0.7898\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 137us/step - loss: 0.3426 - acc: 0.8467 - val_loss: 0.4861 - val_acc: 0.7810\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 165us/step - loss: 0.3164 - acc: 0.8604 - val_loss: 0.4701 - val_acc: 0.7902\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 137us/step - loss: 0.2915 - acc: 0.8739 - val_loss: 0.4757 - val_acc: 0.7876\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 135us/step - loss: 0.2714 - acc: 0.8834 - val_loss: 0.5167 - val_acc: 0.7826\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 144us/step - loss: 0.2507 - acc: 0.8922 - val_loss: 0.5495 - val_acc: 0.7818\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.2275 - acc: 0.9047 - val_loss: 0.5399 - val_acc: 0.7854\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 124us/step - loss: 0.2078 - acc: 0.9136 - val_loss: 0.5868 - val_acc: 0.7902\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.1894 - acc: 0.9233 - val_loss: 0.6128 - val_acc: 0.7864\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 2s 109us/step - loss: 0.1707 - acc: 0.9331 - val_loss: 0.6432 - val_acc: 0.7898\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.1497 - acc: 0.9394 - val_loss: 0.7115 - val_acc: 0.7796\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.1308 - acc: 0.9492 - val_loss: 0.7544 - val_acc: 0.7812\n",
      "['3-conv-32-nodes-3-dense-1548439050']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 148us/step - loss: 0.6549 - acc: 0.5978 - val_loss: 0.6112 - val_acc: 0.6645\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 132us/step - loss: 0.5656 - acc: 0.7089 - val_loss: 0.5428 - val_acc: 0.7261\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.5165 - acc: 0.7457 - val_loss: 0.5032 - val_acc: 0.7521\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.4781 - acc: 0.7712 - val_loss: 0.5166 - val_acc: 0.7447\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 2s 122us/step - loss: 0.4538 - acc: 0.7854 - val_loss: 0.4811 - val_acc: 0.7721\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.4282 - acc: 0.8042 - val_loss: 0.4584 - val_acc: 0.7868\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 2s 119us/step - loss: 0.4059 - acc: 0.8132 - val_loss: 0.4477 - val_acc: 0.7944\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.3789 - acc: 0.8285 - val_loss: 0.4292 - val_acc: 0.8064\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.3555 - acc: 0.8406 - val_loss: 0.4495 - val_acc: 0.7928\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.3383 - acc: 0.8501 - val_loss: 0.4481 - val_acc: 0.8034\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.3197 - acc: 0.8592 - val_loss: 0.4578 - val_acc: 0.8086\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.3027 - acc: 0.8671 - val_loss: 0.4533 - val_acc: 0.8070\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 2s 119us/step - loss: 0.2876 - acc: 0.8754 - val_loss: 0.4616 - val_acc: 0.8042\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 149us/step - loss: 0.2706 - acc: 0.8830 - val_loss: 0.4604 - val_acc: 0.7920\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.2549 - acc: 0.8907 - val_loss: 0.4605 - val_acc: 0.8058\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.2424 - acc: 0.8989 - val_loss: 0.5080 - val_acc: 0.8062\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 120us/step - loss: 0.2262 - acc: 0.9039 - val_loss: 0.4972 - val_acc: 0.8112\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.2117 - acc: 0.9133 - val_loss: 0.5227 - val_acc: 0.8010\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 119us/step - loss: 0.2018 - acc: 0.9146 - val_loss: 0.5243 - val_acc: 0.8064\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 2s 119us/step - loss: 0.1869 - acc: 0.9233 - val_loss: 0.5654 - val_acc: 0.8030\n",
      "['1-conv-64-nodes-1-dense-1548439101']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 181us/step - loss: 0.6095 - acc: 0.6608 - val_loss: 0.5855 - val_acc: 0.6970\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.5249 - acc: 0.7402 - val_loss: 0.5266 - val_acc: 0.7383\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.4766 - acc: 0.7723 - val_loss: 0.5300 - val_acc: 0.7377\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 4s 191us/step - loss: 0.4370 - acc: 0.7975 - val_loss: 0.5304 - val_acc: 0.7473\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.3860 - acc: 0.8251 - val_loss: 0.5576 - val_acc: 0.7321\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.3266 - acc: 0.8570 - val_loss: 0.5797 - val_acc: 0.7403\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.2620 - acc: 0.8914 - val_loss: 0.6263 - val_acc: 0.7317\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.1986 - acc: 0.9221 - val_loss: 0.6788 - val_acc: 0.7357\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.1356 - acc: 0.9528 - val_loss: 0.7929 - val_acc: 0.7321\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.0939 - acc: 0.9677 - val_loss: 0.9448 - val_acc: 0.7285\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.0579 - acc: 0.9845 - val_loss: 1.0284 - val_acc: 0.7377\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.0455 - acc: 0.9884 - val_loss: 1.1573 - val_acc: 0.7160\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 4s 180us/step - loss: 0.0323 - acc: 0.9918 - val_loss: 1.2625 - val_acc: 0.7162\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.0293 - acc: 0.9926 - val_loss: 1.3055 - val_acc: 0.7251\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.0350 - acc: 0.9905 - val_loss: 1.3652 - val_acc: 0.7309\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.0255 - acc: 0.9934 - val_loss: 1.4875 - val_acc: 0.7210\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.0243 - acc: 0.9928 - val_loss: 1.5012 - val_acc: 0.7204\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.0333 - acc: 0.9896 - val_loss: 1.5574 - val_acc: 0.7162\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 169us/step - loss: 0.0160 - acc: 0.9963 - val_loss: 1.6097 - val_acc: 0.7234\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.0157 - acc: 0.9955 - val_loss: 1.7381 - val_acc: 0.7164\n",
      "['2-conv-64-nodes-2-dense-1548439171']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 186us/step - loss: 0.6332 - acc: 0.6268 - val_loss: 0.5707 - val_acc: 0.7070\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.5231 - acc: 0.7432 - val_loss: 0.5284 - val_acc: 0.7465\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.4704 - acc: 0.7728 - val_loss: 0.4800 - val_acc: 0.7675\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 3s 157us/step - loss: 0.4370 - acc: 0.7942 - val_loss: 0.4700 - val_acc: 0.7766\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.3969 - acc: 0.8191 - val_loss: 0.4723 - val_acc: 0.7822\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 157us/step - loss: 0.3558 - acc: 0.8430 - val_loss: 0.4676 - val_acc: 0.7856\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.3074 - acc: 0.8644 - val_loss: 0.4837 - val_acc: 0.7824\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.2592 - acc: 0.8907 - val_loss: 0.5132 - val_acc: 0.7854\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 157us/step - loss: 0.2121 - acc: 0.9128 - val_loss: 0.5547 - val_acc: 0.7886\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 165us/step - loss: 0.1669 - acc: 0.9332 - val_loss: 0.6497 - val_acc: 0.7768\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.1240 - acc: 0.9547 - val_loss: 0.6622 - val_acc: 0.7816\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.0890 - acc: 0.9676 - val_loss: 0.7481 - val_acc: 0.7810\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.0625 - acc: 0.9806 - val_loss: 0.8721 - val_acc: 0.7846\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.0480 - acc: 0.9858 - val_loss: 0.9707 - val_acc: 0.7860\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 157us/step - loss: 0.0342 - acc: 0.9893 - val_loss: 1.0765 - val_acc: 0.7790\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.0346 - acc: 0.9895 - val_loss: 1.0776 - val_acc: 0.7760\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 157us/step - loss: 0.0348 - acc: 0.9888 - val_loss: 1.1203 - val_acc: 0.7800\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.0305 - acc: 0.9906 - val_loss: 1.1491 - val_acc: 0.7818\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 160us/step - loss: 0.0167 - acc: 0.9955 - val_loss: 1.5100 - val_acc: 0.7697\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 173us/step - loss: 0.0268 - acc: 0.9918 - val_loss: 1.3748 - val_acc: 0.7667\n",
      "['3-conv-64-nodes-3-dense-1548439237']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 180us/step - loss: 0.6389 - acc: 0.6250 - val_loss: 0.5858 - val_acc: 0.6856\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.5159 - acc: 0.7432 - val_loss: 0.4878 - val_acc: 0.7671\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.4548 - acc: 0.7838 - val_loss: 0.4521 - val_acc: 0.7854\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 3s 163us/step - loss: 0.4022 - acc: 0.8170 - val_loss: 0.4354 - val_acc: 0.8018\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 165us/step - loss: 0.3668 - acc: 0.8344 - val_loss: 0.4181 - val_acc: 0.8116\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.3333 - acc: 0.8542 - val_loss: 0.4268 - val_acc: 0.8164\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.3014 - acc: 0.8679 - val_loss: 0.4200 - val_acc: 0.8078\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 4s 184us/step - loss: 0.2705 - acc: 0.8835 - val_loss: 0.4236 - val_acc: 0.8232\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 175us/step - loss: 0.2371 - acc: 0.8997 - val_loss: 0.4375 - val_acc: 0.8287\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 163us/step - loss: 0.2056 - acc: 0.9145 - val_loss: 0.4801 - val_acc: 0.8216\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.1776 - acc: 0.9272 - val_loss: 0.5338 - val_acc: 0.8094\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.1577 - acc: 0.9361 - val_loss: 0.5743 - val_acc: 0.8030\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 163us/step - loss: 0.1351 - acc: 0.9460 - val_loss: 0.5690 - val_acc: 0.8172\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.1156 - acc: 0.9543 - val_loss: 0.6434 - val_acc: 0.8116\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.0972 - acc: 0.9619 - val_loss: 0.6859 - val_acc: 0.8210\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 168us/step - loss: 0.0825 - acc: 0.9684 - val_loss: 0.7234 - val_acc: 0.8140\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.0846 - acc: 0.9666 - val_loss: 0.7512 - val_acc: 0.8118\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 165us/step - loss: 0.0588 - acc: 0.9779 - val_loss: 0.8296 - val_acc: 0.8122\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.0623 - acc: 0.9765 - val_loss: 0.8579 - val_acc: 0.8018\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 164us/step - loss: 0.0529 - acc: 0.9799 - val_loss: 0.8398 - val_acc: 0.8132\n",
      "['1-conv-128-nodes-1-dense-1548439306']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 8s 401us/step - loss: 0.6170 - acc: 0.6609 - val_loss: 0.5680 - val_acc: 0.7176\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 8s 385us/step - loss: 0.5326 - acc: 0.7354 - val_loss: 0.6129 - val_acc: 0.6846\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 8s 396us/step - loss: 0.4831 - acc: 0.7699 - val_loss: 0.5287 - val_acc: 0.7341\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 8s 382us/step - loss: 0.4387 - acc: 0.7938 - val_loss: 0.5402 - val_acc: 0.7389\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 8s 386us/step - loss: 0.3937 - acc: 0.8194 - val_loss: 0.5577 - val_acc: 0.7301\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 8s 382us/step - loss: 0.3314 - acc: 0.8536 - val_loss: 0.5808 - val_acc: 0.7417\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 8s 391us/step - loss: 0.2676 - acc: 0.8848 - val_loss: 0.6367 - val_acc: 0.7238\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 8s 383us/step - loss: 0.2025 - acc: 0.9190 - val_loss: 0.7320 - val_acc: 0.7319\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 8s 386us/step - loss: 0.1479 - acc: 0.9446 - val_loss: 0.8104 - val_acc: 0.7311\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 8s 397us/step - loss: 0.0964 - acc: 0.9677 - val_loss: 0.9168 - val_acc: 0.7257\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 8s 384us/step - loss: 0.0677 - acc: 0.9788 - val_loss: 1.0133 - val_acc: 0.7222\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 8s 385us/step - loss: 0.0486 - acc: 0.9857 - val_loss: 1.0629 - val_acc: 0.7206\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 8s 388us/step - loss: 0.0429 - acc: 0.9879 - val_loss: 1.2412 - val_acc: 0.7273\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 8s 389us/step - loss: 0.0395 - acc: 0.9881 - val_loss: 1.3118 - val_acc: 0.7271\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 8s 385us/step - loss: 0.0209 - acc: 0.9951 - val_loss: 1.4180 - val_acc: 0.7295\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 8s 386us/step - loss: 0.0281 - acc: 0.9921 - val_loss: 1.5266 - val_acc: 0.7212\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 8s 387us/step - loss: 0.0367 - acc: 0.9896 - val_loss: 1.4888 - val_acc: 0.7160\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 8s 391us/step - loss: 0.0174 - acc: 0.9952 - val_loss: 1.5307 - val_acc: 0.7198\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 8s 389us/step - loss: 0.0224 - acc: 0.9938 - val_loss: 1.5298 - val_acc: 0.7210\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 8s 384us/step - loss: 0.0182 - acc: 0.9946 - val_loss: 1.6509 - val_acc: 0.7170\n",
      "['2-conv-128-nodes-2-dense-1548439462']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 6s 314us/step - loss: 0.6622 - acc: 0.5844 - val_loss: 0.6030 - val_acc: 0.6798\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 6s 311us/step - loss: 0.5712 - acc: 0.7045 - val_loss: 0.5329 - val_acc: 0.7325\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 6s 309us/step - loss: 0.4925 - acc: 0.7641 - val_loss: 0.4918 - val_acc: 0.7699\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 6s 306us/step - loss: 0.4463 - acc: 0.7895 - val_loss: 0.4629 - val_acc: 0.7842\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 6s 300us/step - loss: 0.4090 - acc: 0.8138 - val_loss: 0.4658 - val_acc: 0.7928\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 6s 302us/step - loss: 0.3640 - acc: 0.8382 - val_loss: 0.4535 - val_acc: 0.7930\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 6s 309us/step - loss: 0.3255 - acc: 0.8576 - val_loss: 0.4449 - val_acc: 0.7940\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 6s 306us/step - loss: 0.2760 - acc: 0.8793 - val_loss: 0.5064 - val_acc: 0.7928\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 6s 307us/step - loss: 0.2200 - acc: 0.9105 - val_loss: 0.5362 - val_acc: 0.7908\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 6s 302us/step - loss: 0.1749 - acc: 0.9287 - val_loss: 0.5812 - val_acc: 0.7936\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 6s 303us/step - loss: 0.1320 - acc: 0.9506 - val_loss: 0.6463 - val_acc: 0.7872\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 6s 311us/step - loss: 0.0945 - acc: 0.9674 - val_loss: 0.7686 - val_acc: 0.7970\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 6s 308us/step - loss: 0.0656 - acc: 0.9770 - val_loss: 0.8063 - val_acc: 0.7796\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 6s 309us/step - loss: 0.0475 - acc: 0.9855 - val_loss: 0.8975 - val_acc: 0.7878\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 6s 294us/step - loss: 0.0443 - acc: 0.9855 - val_loss: 1.0274 - val_acc: 0.7844\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 6s 301us/step - loss: 0.0441 - acc: 0.9850 - val_loss: 1.0919 - val_acc: 0.7826\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 6s 307us/step - loss: 0.0270 - acc: 0.9920 - val_loss: 1.1601 - val_acc: 0.7814\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 6s 304us/step - loss: 0.0202 - acc: 0.9939 - val_loss: 1.2362 - val_acc: 0.7778\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 6s 306us/step - loss: 0.0376 - acc: 0.9868 - val_loss: 1.2492 - val_acc: 0.7776\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 6s 306us/step - loss: 0.0197 - acc: 0.9942 - val_loss: 1.2814 - val_acc: 0.7834\n",
      "['3-conv-128-nodes-3-dense-1548439587']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 6s 317us/step - loss: 0.6553 - acc: 0.5977 - val_loss: 0.6187 - val_acc: 0.6621\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 6s 313us/step - loss: 0.5339 - acc: 0.7306 - val_loss: 0.5473 - val_acc: 0.7253\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 6s 296us/step - loss: 0.4638 - acc: 0.7815 - val_loss: 0.4603 - val_acc: 0.7786\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 6s 294us/step - loss: 0.4095 - acc: 0.8120 - val_loss: 0.4195 - val_acc: 0.8084\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 6s 291us/step - loss: 0.3665 - acc: 0.8358 - val_loss: 0.4366 - val_acc: 0.8100\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 6s 295us/step - loss: 0.3358 - acc: 0.8528 - val_loss: 0.4083 - val_acc: 0.8120\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 6s 304us/step - loss: 0.2964 - acc: 0.8707 - val_loss: 0.4388 - val_acc: 0.8018\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 6s 305us/step - loss: 0.2606 - acc: 0.8896 - val_loss: 0.4914 - val_acc: 0.8076\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 6s 289us/step - loss: 0.2269 - acc: 0.9041 - val_loss: 0.4720 - val_acc: 0.8244\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 6s 307us/step - loss: 0.1913 - acc: 0.9201 - val_loss: 0.4811 - val_acc: 0.8128\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 6s 309us/step - loss: 0.1509 - acc: 0.9379 - val_loss: 0.5383 - val_acc: 0.8196\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 6s 292us/step - loss: 0.1297 - acc: 0.9475 - val_loss: 0.6113 - val_acc: 0.8074\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 6s 288us/step - loss: 0.1056 - acc: 0.9589 - val_loss: 0.6697 - val_acc: 0.8092\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 6s 302us/step - loss: 0.0945 - acc: 0.9636 - val_loss: 0.7180 - val_acc: 0.7988\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 6s 290us/step - loss: 0.0719 - acc: 0.9734 - val_loss: 0.8025 - val_acc: 0.8112\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 6s 299us/step - loss: 0.0644 - acc: 0.9755 - val_loss: 0.8484 - val_acc: 0.7924\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 6s 295us/step - loss: 0.0544 - acc: 0.9794 - val_loss: 0.7976 - val_acc: 0.8148\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 6s 306us/step - loss: 0.0506 - acc: 0.9818 - val_loss: 0.8681 - val_acc: 0.8064\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 6s 296us/step - loss: 0.0554 - acc: 0.9800 - val_loss: 0.8555 - val_acc: 0.8136\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 6s 292us/step - loss: 0.0414 - acc: 0.9854 - val_loss: 0.9825 - val_acc: 0.8028\n",
      "['1-conv-32-nodes-1-dense-1548439708']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 132us/step - loss: 0.6217 - acc: 0.6464 - val_loss: 0.5520 - val_acc: 0.7279\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 144us/step - loss: 0.5268 - acc: 0.7403 - val_loss: 0.5366 - val_acc: 0.7363\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 127us/step - loss: 0.4799 - acc: 0.7720 - val_loss: 0.5715 - val_acc: 0.7204\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.4400 - acc: 0.7983 - val_loss: 0.5270 - val_acc: 0.7399\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.4026 - acc: 0.8184 - val_loss: 0.5562 - val_acc: 0.7405\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.3484 - acc: 0.8449 - val_loss: 0.6108 - val_acc: 0.7246\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.3002 - acc: 0.8717 - val_loss: 0.6527 - val_acc: 0.7313\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.2478 - acc: 0.8970 - val_loss: 0.7404 - val_acc: 0.7238\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.1999 - acc: 0.9199 - val_loss: 0.8076 - val_acc: 0.7317\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.1589 - acc: 0.9377 - val_loss: 0.9526 - val_acc: 0.7158\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.1267 - acc: 0.9518 - val_loss: 1.1202 - val_acc: 0.7132\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.1067 - acc: 0.9587 - val_loss: 1.1594 - val_acc: 0.7124\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 2s 113us/step - loss: 0.0831 - acc: 0.9716 - val_loss: 1.2599 - val_acc: 0.7124\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 2s 116us/step - loss: 0.0800 - acc: 0.9715 - val_loss: 1.4325 - val_acc: 0.7122\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 152us/step - loss: 0.0620 - acc: 0.9787 - val_loss: 1.4528 - val_acc: 0.7076\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.0514 - acc: 0.9818 - val_loss: 1.6644 - val_acc: 0.7082\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.0559 - acc: 0.9802 - val_loss: 1.7701 - val_acc: 0.7018\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 2s 115us/step - loss: 0.0444 - acc: 0.9842 - val_loss: 1.7115 - val_acc: 0.7072\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 114us/step - loss: 0.0471 - acc: 0.9824 - val_loss: 1.8943 - val_acc: 0.7010\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 2s 116us/step - loss: 0.0512 - acc: 0.9820 - val_loss: 1.7554 - val_acc: 0.7062\n",
      "['2-conv-32-nodes-2-dense-1548439758']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 142us/step - loss: 0.6110 - acc: 0.6603 - val_loss: 0.5971 - val_acc: 0.6848\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.5287 - acc: 0.7355 - val_loss: 0.5154 - val_acc: 0.7461\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.4881 - acc: 0.7653 - val_loss: 0.4907 - val_acc: 0.7669\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.4561 - acc: 0.7844 - val_loss: 0.4704 - val_acc: 0.7723\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.4335 - acc: 0.7996 - val_loss: 0.4692 - val_acc: 0.7780\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 149us/step - loss: 0.4050 - acc: 0.8156 - val_loss: 0.4763 - val_acc: 0.7760\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 139us/step - loss: 0.3786 - acc: 0.8289 - val_loss: 0.4528 - val_acc: 0.7934\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.3566 - acc: 0.8392 - val_loss: 0.4900 - val_acc: 0.7715\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 2s 122us/step - loss: 0.3373 - acc: 0.8464 - val_loss: 0.5003 - val_acc: 0.7878\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 2s 122us/step - loss: 0.3029 - acc: 0.8686 - val_loss: 0.5093 - val_acc: 0.7758\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.2793 - acc: 0.8778 - val_loss: 0.5265 - val_acc: 0.7852\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.2510 - acc: 0.8917 - val_loss: 0.5339 - val_acc: 0.7888\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.2240 - acc: 0.9041 - val_loss: 0.5790 - val_acc: 0.7858\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.1971 - acc: 0.9188 - val_loss: 0.6138 - val_acc: 0.7790\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 2s 123us/step - loss: 0.1709 - acc: 0.9298 - val_loss: 0.6832 - val_acc: 0.7890\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.1518 - acc: 0.9381 - val_loss: 0.7519 - val_acc: 0.7689\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 2s 121us/step - loss: 0.1219 - acc: 0.9512 - val_loss: 0.8302 - val_acc: 0.7651\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 147us/step - loss: 0.1080 - acc: 0.9574 - val_loss: 0.9084 - val_acc: 0.7707\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 2s 124us/step - loss: 0.0988 - acc: 0.9616 - val_loss: 0.9907 - val_acc: 0.7768\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 2s 122us/step - loss: 0.0790 - acc: 0.9702 - val_loss: 1.1335 - val_acc: 0.7780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3-conv-32-nodes-3-dense-1548439811']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 3s 154us/step - loss: 0.6452 - acc: 0.6123 - val_loss: 0.5750 - val_acc: 0.7046\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 135us/step - loss: 0.5314 - acc: 0.7343 - val_loss: 0.5102 - val_acc: 0.7549\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.4809 - acc: 0.7693 - val_loss: 0.4764 - val_acc: 0.7749\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 3s 135us/step - loss: 0.4442 - acc: 0.7925 - val_loss: 0.4614 - val_acc: 0.7830\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.4097 - acc: 0.8112 - val_loss: 0.4474 - val_acc: 0.8006\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 135us/step - loss: 0.3829 - acc: 0.8269 - val_loss: 0.4478 - val_acc: 0.7924\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 134us/step - loss: 0.3613 - acc: 0.8396 - val_loss: 0.5298 - val_acc: 0.7653\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 155us/step - loss: 0.3397 - acc: 0.8510 - val_loss: 0.4840 - val_acc: 0.7862\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.3194 - acc: 0.8607 - val_loss: 0.4468 - val_acc: 0.8060\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.2938 - acc: 0.8761 - val_loss: 0.4661 - val_acc: 0.8112\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 134us/step - loss: 0.2764 - acc: 0.8829 - val_loss: 0.4807 - val_acc: 0.7958\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.2566 - acc: 0.8889 - val_loss: 0.4650 - val_acc: 0.8094\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 134us/step - loss: 0.2352 - acc: 0.9017 - val_loss: 0.5709 - val_acc: 0.7886\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.2198 - acc: 0.9101 - val_loss: 0.4865 - val_acc: 0.8076\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 134us/step - loss: 0.1972 - acc: 0.9177 - val_loss: 0.5270 - val_acc: 0.8038\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.1843 - acc: 0.9241 - val_loss: 0.6349 - val_acc: 0.7964\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 134us/step - loss: 0.1701 - acc: 0.9313 - val_loss: 0.5908 - val_acc: 0.8012\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 133us/step - loss: 0.1584 - acc: 0.9371 - val_loss: 0.5771 - val_acc: 0.8108\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 160us/step - loss: 0.1452 - acc: 0.9425 - val_loss: 0.6279 - val_acc: 0.8018\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 135us/step - loss: 0.1358 - acc: 0.9458 - val_loss: 0.6985 - val_acc: 0.7970\n",
      "['1-conv-64-nodes-1-dense-1548439869']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 197us/step - loss: 0.6168 - acc: 0.6582 - val_loss: 0.5704 - val_acc: 0.7090\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.5226 - acc: 0.7435 - val_loss: 0.5417 - val_acc: 0.7261\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 4s 179us/step - loss: 0.4698 - acc: 0.7734 - val_loss: 0.5386 - val_acc: 0.7411\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.4086 - acc: 0.8122 - val_loss: 0.5468 - val_acc: 0.7453\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.3357 - acc: 0.8510 - val_loss: 0.6304 - val_acc: 0.7279\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.2468 - acc: 0.8939 - val_loss: 0.7379 - val_acc: 0.7315\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 4s 209us/step - loss: 0.1762 - acc: 0.9309 - val_loss: 0.9055 - val_acc: 0.7226\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.1132 - acc: 0.9569 - val_loss: 1.1237 - val_acc: 0.7204\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 4s 180us/step - loss: 0.0780 - acc: 0.9716 - val_loss: 1.2994 - val_acc: 0.7283\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.0610 - acc: 0.9785 - val_loss: 1.4253 - val_acc: 0.7138\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 4s 179us/step - loss: 0.0564 - acc: 0.9821 - val_loss: 1.5755 - val_acc: 0.7220\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.0518 - acc: 0.9830 - val_loss: 1.5446 - val_acc: 0.7066\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.0361 - acc: 0.9884 - val_loss: 1.6148 - val_acc: 0.7160\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.0314 - acc: 0.9912 - val_loss: 1.7085 - val_acc: 0.7246\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 4s 197us/step - loss: 0.0345 - acc: 0.9882 - val_loss: 1.8319 - val_acc: 0.7062\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 4s 179us/step - loss: 0.0422 - acc: 0.9864 - val_loss: 2.0024 - val_acc: 0.7106\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.0325 - acc: 0.9892 - val_loss: 1.8059 - val_acc: 0.7140\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 4s 179us/step - loss: 0.0297 - acc: 0.9911 - val_loss: 1.9499 - val_acc: 0.7148\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.0213 - acc: 0.9934 - val_loss: 2.0447 - val_acc: 0.7134\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.0290 - acc: 0.9901 - val_loss: 1.9309 - val_acc: 0.7106\n",
      "['2-conv-64-nodes-2-dense-1548439944']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 191us/step - loss: 0.6057 - acc: 0.6622 - val_loss: 0.5230 - val_acc: 0.7481\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 169us/step - loss: 0.5019 - acc: 0.7558 - val_loss: 0.5006 - val_acc: 0.7621\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 4s 205us/step - loss: 0.4542 - acc: 0.7869 - val_loss: 0.4840 - val_acc: 0.7663\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.4139 - acc: 0.8103 - val_loss: 0.4582 - val_acc: 0.7826\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.3727 - acc: 0.8330 - val_loss: 0.4666 - val_acc: 0.7762\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.3254 - acc: 0.8583 - val_loss: 0.4924 - val_acc: 0.7816\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.2766 - acc: 0.8793 - val_loss: 0.5412 - val_acc: 0.7822\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.2307 - acc: 0.9003 - val_loss: 0.5913 - val_acc: 0.7840\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 3s 171us/step - loss: 0.1852 - acc: 0.9234 - val_loss: 0.6407 - val_acc: 0.7804\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 171us/step - loss: 0.1467 - acc: 0.9389 - val_loss: 0.7501 - val_acc: 0.7872\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 4s 180us/step - loss: 0.1154 - acc: 0.9529 - val_loss: 0.8629 - val_acc: 0.7900\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 4s 193us/step - loss: 0.0949 - acc: 0.9628 - val_loss: 0.9073 - val_acc: 0.7693\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 173us/step - loss: 0.0718 - acc: 0.9718 - val_loss: 1.0228 - val_acc: 0.7715\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.0591 - acc: 0.9775 - val_loss: 1.2122 - val_acc: 0.7856\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.0606 - acc: 0.9776 - val_loss: 1.2273 - val_acc: 0.7832\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 171us/step - loss: 0.0658 - acc: 0.9760 - val_loss: 1.2222 - val_acc: 0.7810\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.0406 - acc: 0.9857 - val_loss: 1.1878 - val_acc: 0.7770\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 3s 169us/step - loss: 0.0397 - acc: 0.9872 - val_loss: 1.2984 - val_acc: 0.7838\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 170us/step - loss: 0.0400 - acc: 0.9858 - val_loss: 1.3514 - val_acc: 0.7749\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 4s 196us/step - loss: 0.0427 - acc: 0.9855 - val_loss: 1.4043 - val_acc: 0.7687\n",
      "['3-conv-64-nodes-3-dense-1548440017']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 200us/step - loss: 0.6426 - acc: 0.6178 - val_loss: 0.5885 - val_acc: 0.6828\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.5250 - acc: 0.7405 - val_loss: 0.5353 - val_acc: 0.7369\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.4592 - acc: 0.7828 - val_loss: 0.4705 - val_acc: 0.7782\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.4119 - acc: 0.8090 - val_loss: 0.4501 - val_acc: 0.7894\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.3759 - acc: 0.8305 - val_loss: 0.4602 - val_acc: 0.7908\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.3350 - acc: 0.8507 - val_loss: 0.4154 - val_acc: 0.8132\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 4s 182us/step - loss: 0.3027 - acc: 0.8688 - val_loss: 0.4213 - val_acc: 0.8242\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 4s 208us/step - loss: 0.2708 - acc: 0.8842 - val_loss: 0.4163 - val_acc: 0.8248\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.2419 - acc: 0.8986 - val_loss: 0.4411 - val_acc: 0.8236\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.2131 - acc: 0.9123 - val_loss: 0.6057 - val_acc: 0.7717\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.1862 - acc: 0.9246 - val_loss: 0.5256 - val_acc: 0.8096\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.1544 - acc: 0.9396 - val_loss: 0.5442 - val_acc: 0.8166\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 4s 178us/step - loss: 0.1411 - acc: 0.9441 - val_loss: 0.5105 - val_acc: 0.8172\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.1133 - acc: 0.9548 - val_loss: 0.6761 - val_acc: 0.8110\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.1099 - acc: 0.9568 - val_loss: 0.6530 - val_acc: 0.8253\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 4s 201us/step - loss: 0.0916 - acc: 0.9649 - val_loss: 0.7250 - val_acc: 0.8130\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.0803 - acc: 0.9707 - val_loss: 0.7305 - val_acc: 0.8076\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.0698 - acc: 0.9739 - val_loss: 0.8103 - val_acc: 0.8164\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.0705 - acc: 0.9737 - val_loss: 0.7901 - val_acc: 0.8044\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.0616 - acc: 0.9772 - val_loss: 0.9075 - val_acc: 0.8024\n",
      "['1-conv-128-nodes-1-dense-1548440092']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 8s 417us/step - loss: 0.6152 - acc: 0.6597 - val_loss: 0.5497 - val_acc: 0.7295\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 8s 413us/step - loss: 0.5114 - acc: 0.7520 - val_loss: 0.5256 - val_acc: 0.7453\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 8s 399us/step - loss: 0.4371 - acc: 0.7963 - val_loss: 0.5507 - val_acc: 0.7283\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 8s 398us/step - loss: 0.3395 - acc: 0.8492 - val_loss: 0.6357 - val_acc: 0.7317\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 8s 409us/step - loss: 0.2261 - acc: 0.9070 - val_loss: 0.7770 - val_acc: 0.7244\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 8s 409us/step - loss: 0.1339 - acc: 0.9487 - val_loss: 0.9357 - val_acc: 0.7206\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 8s 399us/step - loss: 0.0784 - acc: 0.9720 - val_loss: 1.1773 - val_acc: 0.7246\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 8s 397us/step - loss: 0.0577 - acc: 0.9796 - val_loss: 1.3196 - val_acc: 0.7299\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 8s 409us/step - loss: 0.0372 - acc: 0.9880 - val_loss: 1.4899 - val_acc: 0.7259\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 8s 397us/step - loss: 0.0407 - acc: 0.9867 - val_loss: 1.5859 - val_acc: 0.7244\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 8s 404us/step - loss: 0.0400 - acc: 0.9868 - val_loss: 1.6291 - val_acc: 0.7228\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 8s 395us/step - loss: 0.0221 - acc: 0.9936 - val_loss: 1.7594 - val_acc: 0.7228\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 8s 408us/step - loss: 0.0348 - acc: 0.9893 - val_loss: 1.5715 - val_acc: 0.7132\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 8s 400us/step - loss: 0.0222 - acc: 0.9929 - val_loss: 1.7605 - val_acc: 0.7287\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 8s 398us/step - loss: 0.0277 - acc: 0.9908 - val_loss: 1.7334 - val_acc: 0.7162\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 8s 405us/step - loss: 0.0221 - acc: 0.9934 - val_loss: 1.9384 - val_acc: 0.7150\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 8s 411us/step - loss: 0.0161 - acc: 0.9952 - val_loss: 1.9936 - val_acc: 0.7146\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 8s 402us/step - loss: 0.0318 - acc: 0.9897 - val_loss: 1.8799 - val_acc: 0.7162\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 8s 398us/step - loss: 0.0135 - acc: 0.9964 - val_loss: 1.8015 - val_acc: 0.7281\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 8s 411us/step - loss: 0.0113 - acc: 0.9967 - val_loss: 1.8931 - val_acc: 0.7110\n",
      "['2-conv-128-nodes-2-dense-1548440256']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 7s 329us/step - loss: 0.6381 - acc: 0.6267 - val_loss: 0.5686 - val_acc: 0.7028\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 6s 312us/step - loss: 0.5270 - acc: 0.7377 - val_loss: 0.5184 - val_acc: 0.7441\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 6s 319us/step - loss: 0.4644 - acc: 0.7811 - val_loss: 0.4818 - val_acc: 0.7647\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 7s 335us/step - loss: 0.4106 - acc: 0.8114 - val_loss: 0.4596 - val_acc: 0.7868\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 7s 326us/step - loss: 0.3414 - acc: 0.8497 - val_loss: 0.4982 - val_acc: 0.7890\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 6s 316us/step - loss: 0.2639 - acc: 0.8891 - val_loss: 0.5351 - val_acc: 0.7764\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 6s 318us/step - loss: 0.1759 - acc: 0.9304 - val_loss: 0.6581 - val_acc: 0.7842\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 6s 315us/step - loss: 0.1103 - acc: 0.9589 - val_loss: 0.8610 - val_acc: 0.7661\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 7s 330us/step - loss: 0.0803 - acc: 0.9696 - val_loss: 0.9721 - val_acc: 0.7804\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 7s 330us/step - loss: 0.0633 - acc: 0.9771 - val_loss: 0.9876 - val_acc: 0.7782\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 6s 318us/step - loss: 0.0430 - acc: 0.9850 - val_loss: 1.1868 - val_acc: 0.7776\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 6s 312us/step - loss: 0.0414 - acc: 0.9855 - val_loss: 1.2648 - val_acc: 0.7758\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 6s 315us/step - loss: 0.0409 - acc: 0.9855 - val_loss: 1.1475 - val_acc: 0.7721\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 6s 324us/step - loss: 0.0357 - acc: 0.9878 - val_loss: 1.1074 - val_acc: 0.7758\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19956/19956 [==============================] - 6s 323us/step - loss: 0.0231 - acc: 0.9920 - val_loss: 1.3970 - val_acc: 0.7721\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 6s 316us/step - loss: 0.0259 - acc: 0.9906 - val_loss: 1.3382 - val_acc: 0.7607\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 6s 318us/step - loss: 0.0297 - acc: 0.9902 - val_loss: 1.4445 - val_acc: 0.7766\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 6s 322us/step - loss: 0.0252 - acc: 0.9913 - val_loss: 1.4154 - val_acc: 0.7653\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 6s 322us/step - loss: 0.0221 - acc: 0.9931 - val_loss: 1.4575 - val_acc: 0.7703\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 6s 317us/step - loss: 0.0207 - acc: 0.9930 - val_loss: 1.3713 - val_acc: 0.7611\n",
      "['3-conv-128-nodes-3-dense-1548440387']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 7s 337us/step - loss: 0.6844 - acc: 0.5451 - val_loss: 0.6764 - val_acc: 0.5679\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 6s 312us/step - loss: 0.6388 - acc: 0.6368 - val_loss: 0.6219 - val_acc: 0.6705\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 6s 324us/step - loss: 0.5572 - acc: 0.7136 - val_loss: 0.5609 - val_acc: 0.7048\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 6s 317us/step - loss: 0.4860 - acc: 0.7646 - val_loss: 0.4885 - val_acc: 0.7617\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 6s 309us/step - loss: 0.4293 - acc: 0.8010 - val_loss: 0.4463 - val_acc: 0.7916\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 6s 315us/step - loss: 0.3895 - acc: 0.8220 - val_loss: 0.4223 - val_acc: 0.8062\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 6s 317us/step - loss: 0.3553 - acc: 0.8417 - val_loss: 0.4499 - val_acc: 0.8016\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 6s 312us/step - loss: 0.3104 - acc: 0.8641 - val_loss: 0.4475 - val_acc: 0.8086\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 6s 310us/step - loss: 0.2696 - acc: 0.8834 - val_loss: 0.4654 - val_acc: 0.8114\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 6s 304us/step - loss: 0.2378 - acc: 0.9002 - val_loss: 0.4785 - val_acc: 0.8132\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 6s 314us/step - loss: 0.1969 - acc: 0.9185 - val_loss: 0.5077 - val_acc: 0.8110\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 6s 320us/step - loss: 0.1580 - acc: 0.9366 - val_loss: 0.6271 - val_acc: 0.8028\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 6s 307us/step - loss: 0.1397 - acc: 0.9445 - val_loss: 0.5801 - val_acc: 0.8096\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 6s 313us/step - loss: 0.1087 - acc: 0.9577 - val_loss: 0.6676 - val_acc: 0.7936\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 6s 312us/step - loss: 0.0928 - acc: 0.9640 - val_loss: 0.7569 - val_acc: 0.8058\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 6s 311us/step - loss: 0.0875 - acc: 0.9672 - val_loss: 0.8182 - val_acc: 0.8014\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 6s 317us/step - loss: 0.0677 - acc: 0.9744 - val_loss: 0.9313 - val_acc: 0.8092\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 6s 291us/step - loss: 0.0605 - acc: 0.9764 - val_loss: 1.0018 - val_acc: 0.8146\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 6s 301us/step - loss: 0.0649 - acc: 0.9763 - val_loss: 0.8724 - val_acc: 0.8100\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 6s 296us/step - loss: 0.0470 - acc: 0.9835 - val_loss: 0.9382 - val_acc: 0.8002\n"
     ]
    }
   ],
   "source": [
    "# iterate over all parameters in greedy grid search\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            name = ['{}-conv-{}-nodes-{}-dense-{}'.format(conv_layer, layer_size, conv_layer, int(time.time()))]\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
    "            print(name)\n",
    "\n",
    "            # declaring a model\n",
    "            model = Sequential()\n",
    "\n",
    "            # convolution layer with 64 neuros\n",
    "            model.add(Conv2D(filters=(layer_size), kernel_size=(3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            for layer in range(conv_layer - 1):\n",
    "                # convolution layer with 64 neurons\n",
    "                model.add(Conv2D(filters=(layer_size), kernel_size=(3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            # flatten the output\n",
    "            model.add(Flatten())\n",
    "                \n",
    "            for layer in range(dense_layer):\n",
    "                model.add(Dense(units=layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            # dense layer with 64 neurons\n",
    "            # model.add(Dense(units=64))\n",
    "            # model.add(Activation('relu'))\n",
    "\n",
    "            # output layer with sigmoid activation\n",
    "            model.add(Dense(units=1, activation='sigmoid'))\n",
    "            \n",
    "            # compiling the model\n",
    "            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            # fitting the model\n",
    "            model.fit(x=X, y=y, batch_size=32, epochs=20, validation_split=0.2, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tensorboard --logdir='logs/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
