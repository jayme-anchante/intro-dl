{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many parameters we can optmize, for instance, the learning rate, optimizing function, number and types of layers, neurons per layer\n",
    "\n",
    "Let's tweak the number of layers and nodes per layer for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "home = os.getenv('HOME')\n",
    "datadir = os.path.join(home, 'Pictures', 'kagglecatsanddogs_3367a', 'PetImages')\n",
    "\n",
    "# tensorflow variables\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.33)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open(os.path.join(datadir, 'X.pkl'), 'rb') as file:\n",
    "    X = pickle.load(file)\n",
    "    \n",
    "with open(os.path.join(datadir, 'y.pkl'), 'rb') as file:\n",
    "    y = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24946, 50, 50, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter grid\n",
    "dense_layers = [0]\n",
    "layer_sizes = [64]\n",
    "conv_layers = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3-conv-64-nodes-3-dense-1548621921']\n",
      "Train on 19956 samples, validate on 4990 samples\n",
      "Epoch 1/20\n",
      "19956/19956 [==============================] - 4s 198us/step - loss: 0.6412 - acc: 0.6230 - val_loss: 0.5807 - val_acc: 0.7012\n",
      "Epoch 2/20\n",
      "19956/19956 [==============================] - 3s 156us/step - loss: 0.5485 - acc: 0.7233 - val_loss: 0.5141 - val_acc: 0.7513\n",
      "Epoch 3/20\n",
      "19956/19956 [==============================] - 3s 158us/step - loss: 0.4883 - acc: 0.7652 - val_loss: 0.4881 - val_acc: 0.7581\n",
      "Epoch 4/20\n",
      "19956/19956 [==============================] - 3s 155us/step - loss: 0.4496 - acc: 0.7934 - val_loss: 0.4842 - val_acc: 0.7788\n",
      "Epoch 5/20\n",
      "19956/19956 [==============================] - 3s 167us/step - loss: 0.4177 - acc: 0.8087 - val_loss: 0.4445 - val_acc: 0.7962\n",
      "Epoch 6/20\n",
      "19956/19956 [==============================] - 3s 169us/step - loss: 0.3829 - acc: 0.8287 - val_loss: 0.4203 - val_acc: 0.8084\n",
      "Epoch 7/20\n",
      "19956/19956 [==============================] - 3s 161us/step - loss: 0.3584 - acc: 0.8380 - val_loss: 0.4221 - val_acc: 0.8132\n",
      "Epoch 8/20\n",
      "19956/19956 [==============================] - 4s 176us/step - loss: 0.3290 - acc: 0.8555 - val_loss: 0.4282 - val_acc: 0.8044\n",
      "Epoch 9/20\n",
      "19956/19956 [==============================] - 4s 177us/step - loss: 0.3101 - acc: 0.8641 - val_loss: 0.4182 - val_acc: 0.8106\n",
      "Epoch 10/20\n",
      "19956/19956 [==============================] - 3s 173us/step - loss: 0.2806 - acc: 0.8798 - val_loss: 0.4146 - val_acc: 0.8230\n",
      "Epoch 11/20\n",
      "19956/19956 [==============================] - 3s 157us/step - loss: 0.2575 - acc: 0.8895 - val_loss: 0.4600 - val_acc: 0.8074\n",
      "Epoch 12/20\n",
      "19956/19956 [==============================] - 3s 150us/step - loss: 0.2339 - acc: 0.9032 - val_loss: 0.4639 - val_acc: 0.8170\n",
      "Epoch 13/20\n",
      "19956/19956 [==============================] - 3s 150us/step - loss: 0.2127 - acc: 0.9131 - val_loss: 0.4753 - val_acc: 0.8251\n",
      "Epoch 14/20\n",
      "19956/19956 [==============================] - 3s 150us/step - loss: 0.1900 - acc: 0.9208 - val_loss: 0.4723 - val_acc: 0.8076\n",
      "Epoch 15/20\n",
      "19956/19956 [==============================] - 3s 148us/step - loss: 0.1721 - acc: 0.9326 - val_loss: 0.5029 - val_acc: 0.8058\n",
      "Epoch 16/20\n",
      "19956/19956 [==============================] - 3s 152us/step - loss: 0.1572 - acc: 0.9376 - val_loss: 0.5476 - val_acc: 0.8032\n",
      "Epoch 17/20\n",
      "19956/19956 [==============================] - 3s 150us/step - loss: 0.1404 - acc: 0.9448 - val_loss: 0.5504 - val_acc: 0.8172\n",
      "Epoch 18/20\n",
      "19956/19956 [==============================] - 3s 149us/step - loss: 0.1207 - acc: 0.9533 - val_loss: 0.5795 - val_acc: 0.8108\n",
      "Epoch 19/20\n",
      "19956/19956 [==============================] - 3s 149us/step - loss: 0.1065 - acc: 0.9593 - val_loss: 0.6040 - val_acc: 0.8044\n",
      "Epoch 20/20\n",
      "19956/19956 [==============================] - 3s 154us/step - loss: 0.0875 - acc: 0.9682 - val_loss: 0.6271 - val_acc: 0.8204\n"
     ]
    }
   ],
   "source": [
    "# iterate over all parameters in greedy grid search\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            name = ['{}-conv-{}-nodes-{}-dense-{}'.format(conv_layer, layer_size, conv_layer, int(time.time()))]\n",
    "            tensorboard = TensorBoard(log_dir='logs/{}'.format(name))\n",
    "            print(name)\n",
    "\n",
    "            # declaring a model\n",
    "            model = Sequential()\n",
    "\n",
    "            # convolution layer with 64 neuros\n",
    "            model.add(Conv2D(filters=(layer_size), kernel_size=(3, 3), input_shape=X.shape[1:]))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            for layer in range(conv_layer - 1):\n",
    "                # convolution layer with 64 neurons\n",
    "                model.add(Conv2D(filters=(layer_size), kernel_size=(3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "            \n",
    "            # flatten the output\n",
    "            model.add(Flatten())\n",
    "                \n",
    "            for layer in range(dense_layer):\n",
    "                model.add(Dense(units=layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "\n",
    "            # dense layer with 64 neurons\n",
    "            # model.add(Dense(units=64))\n",
    "            # model.add(Activation('relu'))\n",
    "\n",
    "            # output layer with sigmoid activation\n",
    "            model.add(Dense(units=1, activation='sigmoid'))\n",
    "            \n",
    "            # compiling the model\n",
    "            model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            # fitting the model\n",
    "            model.fit(x=X, y=y, batch_size=32, epochs=20, validation_split=0.2, callbacks=[tensorboard])\n",
    "            \n",
    "# save the model\n",
    "model.save(os.path.join(home, 'intro-dl', 'models', '64x3-cnn.model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-27 18:46:26--  https://pythonprogramming.net/static/images/machine-learning/dog.jpg\n",
      "Resolving pythonprogramming.net (pythonprogramming.net)... 104.237.143.20, 2600:3c00::f03c:91ff:fe84:176d\n",
      "Connecting to pythonprogramming.net (pythonprogramming.net)|104.237.143.20|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 60603 (59K) [image/jpeg]\n",
      "Saving to: ‘/home/jayme/Pictures/kagglecatsanddogs_3367a/PetImages/test/dog.jpg’\n",
      "\n",
      "dog.jpg             100%[===================>]  59,18K   156KB/s    in 0,4s    \n",
      "\n",
      "2019-01-27 18:46:27 (156 KB/s) - ‘/home/jayme/Pictures/kagglecatsanddogs_3367a/PetImages/test/dog.jpg’ saved [60603/60603]\n",
      "\n",
      "--2019-01-27 18:46:27--  https://pythonprogramming.net/static/images/machine-learning/cat.jpg\n",
      "Resolving pythonprogramming.net (pythonprogramming.net)... 104.237.143.20, 2600:3c00::f03c:91ff:fe84:176d\n",
      "Connecting to pythonprogramming.net (pythonprogramming.net)|104.237.143.20|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39058 (38K) [image/jpeg]\n",
      "Saving to: ‘/home/jayme/Pictures/kagglecatsanddogs_3367a/PetImages/test/cat.jpg’\n",
      "\n",
      "cat.jpg             100%[===================>]  38,14K   181KB/s    in 0,2s    \n",
      "\n",
      "2019-01-27 18:46:28 (181 KB/s) - ‘/home/jayme/Pictures/kagglecatsanddogs_3367a/PetImages/test/cat.jpg’ saved [39058/39058]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# downloading test images\n",
    "!wget -P ~/Pictures/kagglecatsanddogs_3367a/PetImages/test/ https://pythonprogramming.net/static/images/machine-learning/dog.jpg\n",
    "!wget -P ~/Pictures/kagglecatsanddogs_3367a/PetImages/test/ https://pythonprogramming.net/static/images/machine-learning/cat.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Cat', 'Dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(file_path):\n",
    "    image_size = 50\n",
    "    image_array = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    new_array = cv2.resize(image_array, (image_size, image_size))\n",
    "    return new_array.reshape(-1, image_size, image_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model = tf.keras.models.load_model(os.path.join(home, 'intro-dl', 'models', '64x3-cnn.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dog\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "prediction = model.predict([prepare(file_path=os.path.join(datadir, 'test', 'dog.jpg'))])\n",
    "# pretty print the prediction\n",
    "print(categories[(int(prediction[0][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "prediction = model.predict([prepare(file_path=os.path.join(datadir, 'test', 'cat.jpg'))])\n",
    "# pretty print the prediction\n",
    "print(categories[(int(prediction[0][0]))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
